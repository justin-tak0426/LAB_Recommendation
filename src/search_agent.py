import os
from typing import Dict, List, Any
from datetime import datetime
from dotenv import load_dotenv
from tavily import TavilyClient
from openai import OpenAI, AzureOpenAI

# .env íŒŒì¼ì—ì„œ í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# í™˜ê²½ë³€ìˆ˜ ì½ê¸°
TAVILY_API_KEY = os.getenv("TAVILY_API_KEY")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
AZURE_ENDPOINT = os.getenv("AZURE_OPENAI_ENDPOINT")
OPENAI_API_TYPE = os.getenv("OPENAI_API_TYPE", "openai")  # ê¸°ë³¸ê°’ ì„¤ì •
OPENAI_API_VERSION = os.getenv("OPENAI_API_VERSION")


# ì „ì—­ í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
def _init_clients():
    """API í´ë¼ì´ì–¸íŠ¸ë“¤ì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."""
    
    # Tavily í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
    tavily_client = TavilyClient(api_key=TAVILY_API_KEY)
    
    # OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
    if OPENAI_API_TYPE == "azure":
        openai_client = AzureOpenAI(
            api_key=OPENAI_API_KEY,
            api_version=OPENAI_API_VERSION,
            azure_endpoint=AZURE_ENDPOINT
        )
        print(f"âœ… Azure OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ (ì—”ë“œí¬ì¸íŠ¸: {AZURE_ENDPOINT})")
    else:
        openai_client = OpenAI(api_key=OPENAI_API_KEY)
        print("âœ… OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ")
    
    print("âœ… Tavily í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ")
    return tavily_client, openai_client

# ì „ì—­ í´ë¼ì´ì–¸íŠ¸
tavily_client, openai_client = _init_clients()

def search_web(query: str, max_results: int, status_callback=None) -> Dict[str, Any]:
    """
    ì›¹ê²€ìƒ‰ + GPT ë¶„ì„ì„ ìˆ˜í–‰í•˜ëŠ” ë©”ì¸ í•¨ìˆ˜
    
    ì…ë ¥ í˜•ì‹:
        1. ë‹¨ì¼ ì¿¼ë¦¬: query="ê²€ìƒ‰í•˜ê³  ì‹¶ì€ ë‚´ìš©"
        2. ì˜µì…˜ ì„¤ì •: max_results=5 (ê²€ìƒ‰ ê²°ê³¼ ìˆ˜), include_score=True (ì ìˆ˜ í¬í•¨)
    
    Args:
        query (str): ê²€ìƒ‰í•  ì§ˆì˜
        max_results (int): ê²€ìƒ‰ ê²°ê³¼ ìˆ˜ (1-10, ê¸°ë³¸ê°’: 5)
        include_score (bool): ì ìˆ˜ í¬í•¨ ì—¬ë¶€ (ê¸°ë³¸ê°’: False)
    
    Returns:
        Dict: {
            "query": ì…ë ¥í•œ ì§ˆì˜,
            "answer": GPTê°€ ìƒì„±í•œ ë‹µë³€,
            "score": ë‹µë³€ í’ˆì§ˆ ì ìˆ˜ 1-10 (include_score=Trueì¼ ë•Œë§Œ),
            "sources": ì›¹ ê²€ìƒ‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸,
            "timestamp": ê²€ìƒ‰ ì‹œê°„,
            "model": ì‚¬ìš© ëª¨ë¸ëª…
        }
    
    ì‚¬ìš© ì˜ˆì‹œ:
        # ê¸°ë³¸ ê²€ìƒ‰
        result = search_web("êµ­ë‚´ AI ì—°êµ¬ì†Œ")
        print(result["answer"])
        
        # ì ìˆ˜ í¬í•¨ ê²€ìƒ‰
        result = search_web("êµ­ë‚´ AI ì—°êµ¬ì†Œ", include_score=True)
        print(f"ì ìˆ˜: {result['score']}/10")
        
        # ê²€ìƒ‰ ê²°ê³¼ 10ê°œë¡œ í™•ì¥
        result = search_web("êµ­ë‚´ AI ì—°êµ¬ì†Œ", max_results=10)
    """
    try:
        # 1. Tavilyë¡œ ì›¹ ê²€ìƒ‰
        if status_callback:
            status_callback(f"ğŸŒ '{query}' ì›¹ ê²€ìƒ‰ ì¤‘...")
        else:
            print(f"ğŸŒ '{query}' ê²€ìƒ‰ ì¤‘...")
            
        search_response = tavily_client.search(
            query=query,
            search_depth="advanced",
            max_results=max_results,
            include_answer=True,
            include_raw_content=True
        )
        
        if status_callback:
            status_callback("âœ… ì›¹ ê²€ìƒ‰ ì™„ë£Œ")
        else:
            print("âœ… ì›¹ ê²€ìƒ‰ ì™„ë£Œ")

        # ê²€ìƒ‰ ê²°ê³¼ ì²˜ë¦¬
        sources = []
        if "results" in search_response:
            for item in search_response["results"]:
                sources.append({
                    "title": item.get("title", ""),
                    "url": item.get("url", ""),
                    "content": item.get("content", ""),
                    "published_date": item.get("published_date", "")
                })
                
        # print(f"âœ… {len(sources)}ê°œ ê²°ê³¼ ì°¾ìŒ")
        
        if not sources:
            return 0
        
        # 2. GPTë¡œ ê²°ê³¼ ë¶„ì„
        if status_callback:
            status_callback("ğŸ¤– AI ë¶„ì„ ì¤‘...")
        else:
            print("ğŸ¤– GPT ë¶„ì„ ì¤‘...")
        
        # ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
        context = "ì›¹ ê²€ìƒ‰ ê²°ê³¼:\n\n"
        for i, source in enumerate(sources, 1):
            context += f"[ì¶œì²˜ {i}] {source['title']}\n"
            context += f"URL: {source['url']}\n"
            context += f"ë‚´ìš©: {source['content']}\n\n"
        
        messages = [
            {
                "role": "system",
                "content": f"""
ë‹¤ìŒ ì›ì¹™ì— ë”°ë¼ ë‹µë³€í•´ì£¼ì„¸ìš”:
1. ê²€ìƒ‰ëœ ì‹¤ì œ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ì‹¤ì ì´ê³  ì •í™•í•œ ë‹µë³€ ì œê³µ
2. ì—¬ëŸ¬ ì¶œì²˜ì˜ ì •ë³´ë¥¼ ì¢…í•©í•˜ì—¬ í¬ê´„ì ì¸ ë‹µë³€ ì‘ì„±
3. êµ¬ì²´ì ì´ê³  ì‹¤ìš©ì ì¸ ì •ë³´ í¬í•¨
4. ì¶œì²˜ ì •ë³´ ì ì ˆíˆ ì–¸ê¸‰í•˜ì—¬ ì‹ ë¢°ì„± ì œê³ """
            },
            {
                "role": "user",
                "content": f"""ì§ˆë¬¸: {query}

{context}

ìœ„ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ëŒ€í•œ ì •í™•í•˜ê³  ë„ì›€ì´ ë˜ëŠ” ë‹µë³€ì„ ì‘ì„±í•´ì£¼ì„¸ìš”."""
            }
        ]
        
        gpt_response = openai_client.chat.completions.create(
            model="gpt-4o",
            messages=messages,
            temperature=0.7,
            max_tokens=1024,
        )
        
        answer = gpt_response.choices[0].message.content
        
        
        
        if status_callback:
            status_callback("âœ… ë¶„ì„ ì™„ë£Œ")
        else:
            print("âœ… ë¶„ì„ ì™„ë£Œ")
        
        # kê°œë¡œ ë¶„í• í•˜ì—¬ ë°˜í™˜
        recommendations = []
        if max_results > 1:
            # GPTì—ê²Œ kê°œë¡œ ë‚˜ëˆ„ì–´ ë‹¬ë¼ê³  ìš”ì²­
            split_prompt = f"ë‹¤ìŒ ë‚´ìš©ì„ ì •í™•íˆ {max_results}ê°œì˜ ê°œë³„ ì¶”ì²œìœ¼ë¡œ ë‚˜ëˆ„ì–´ ì£¼ì„¸ìš”. ê°ê°ì„ '===ì¶”ì²œ1===', '===ì¶”ì²œ2===' í˜•ì‹ìœ¼ë¡œ êµ¬ë¶„í•´ ì£¼ì„¸ìš”:\n\n{answer}"
            
            split_response = openai_client.chat.completions.create(
                model="gpt-4o",
                messages=[{"role": "user", "content": split_prompt}],
                temperature=0.3,
                max_tokens=2048,
            )
            
            split_answer = split_response.choices[0].message.content
            parts = split_answer.split("===ì¶”ì²œ")
            
            for i in range(1, min(len(parts), max_results + 1)):
                part = parts[i]
                if part.startswith(str(i) + "==="):
                    content = part[len(str(i) + "==="):].strip()
                elif "===" in part:
                    content = part.split("===", 1)[1].strip()
                else:
                    content = part.strip()
                
                if content:
                    recommendations.append({
                        "index": -1,
                        "lab_info": content,
                        "recommendation_reason": content
                    })
        
        # ë¶„í•  ì‹¤íŒ¨í•˜ê±°ë‚˜ k=1ì¸ ê²½ìš° ì›ë³¸ ë°˜í™˜
        if len(recommendations) == 0:
            recommendations = [{
                "index": -1,
                "lab_info": answer,
                "recommendation_reason": answer
            }]
        
        # kê°œ ë§ì¶”ê¸°
        while len(recommendations) < max_results:
            recommendations.append(recommendations[-1].copy())
            
        return recommendations[:max_results]
        
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        # ì˜¤ë¥˜ ì‹œì—ë„ kê°œ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜
        return [{"index": -1, "lab_info": f"ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {str(e)}", "recommendation_reason": f"ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {str(e)}"}] * max_results